{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoP6+JZyFSmxVRQpfCefK2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Yield Estimation**\n",
        "> **Crop yield** is a standard measurement of the amount of agricultural production harvested per unit of land area. Why is it important?\n",
        "+ It provides valuable information for planning, resource management, and making informed crop production decisions. Additionally, it helps improve food security, increase the efficiency of food production and reduce food waste"
      ],
      "metadata": {
        "id": "1TYAHfxr3Dcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 💡 **Insight**\n",
        "\n",
        "> Despite being an agriculture-specific task, crop yield estimation maps to a well-defined concept in Artificial Intelligence; **regression**. This exercise involves training a model to predict a _continuous variable_, `Production`, hence is a **regression** task."
      ],
      "metadata": {
        "id": "3NBWWEiJ1oCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The dataset**\n",
        "> **Citation:** The dataset used in this exercise encompasses agricultural data for multiple crops cultivated across various states in **India** (_since I couldn't find any open-source datasets for Kenya_) from the year **1997** till **2020**.\n",
        "+ The dataset provides crucial features related to crop yield prediction, and can be found on the [`Kaggle`](https://www.kaggle.com/) website [`here`](https://www.kaggle.com/datasets/akshatgupta7/crop-yield-in-indian-states-dataset)"
      ],
      "metadata": {
        "id": "uoaQQKV711t6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The dataset contains the following columns\n",
        "+ `Crop` - The name of the crop cultivated\n",
        "+ `Crop_Year` - The year in which the crop was grown\n",
        "+ `Season` - The specific cropping season (_Kharif, Rabi, Whole Year, Summer, Winter or Autumn_)\n",
        "+ `State` - The Indian state where the crop was cultivated\n",
        "+ `Area` - The total land area (in hectares) under cultivation for the specific crop (_ha_)\n",
        "+ `Production` - The quantity of crop produced (_Tons_)\n",
        "+ `Annual_Rainfall` - The annual rainfall received in the crop-growing region (_mm_)\n",
        "+ `Fertilizer` - The total amount of fertilizer used for the crop (_kg_)\n",
        "+ `Pesticide` - The total amount of pesticide used for the crop (_kg_)\n",
        "+ `Yield` - The calculated crop yield (production per unit area) _[Tons/ha]_"
      ],
      "metadata": {
        "id": "zg3gghzX29dR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 📝 **Note**  \n",
        "\n",
        "> The `Production` column is the _target / label_ _(y value)_ we want to train the model to predict. The rest of the columns are known as _features_ _(x values)_ in Machine Learning lingo  \n",
        "\n",
        "> Also, some of the rows and columns will be dropped, and not all will be included in model training. Particularly\n",
        "+ `Crop_Year` - Since I'd wish to predict crop yield irrespective of the year the crop was cultivated\n",
        "+ `Yield` - Since this is a derived quantity, and can simply be calculated after inferencing as `Production / Area`"
      ],
      "metadata": {
        "id": "FtqJqpyr3Pya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Library Versions**\n",
        "> For the sake of future reference and comparison, I'll print the versions of all the libraries I used for this exercise"
      ],
      "metadata": {
        "id": "JsJro6pWjmcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install optuna & xgboost\n",
        "!pip install optuna xgboost"
      ],
      "metadata": {
        "id": "wMOInc3aiIQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import optuna, xgboost, matplotlib, pandas, seaborn, sys, sklearn"
      ],
      "metadata": {
        "id": "PwbcVDUYiwoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('System version: ',sys.version)\n",
        "print('optuna version:', optuna.__version__)\n",
        "print('xgboost version: ', xgboost.__version__)\n",
        "print('pandas version: ', pandas.__version__)\n",
        "print('seaborn version: ', seaborn.__version__)\n",
        "print('matplotlib version: ', matplotlib.__version__)\n",
        "print('scikit-learn version', sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HOAWKWCiSqn",
        "outputId": "f9ef5d45-dbd9-4687-e78b-2de265510642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System version:  3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
            "optuna version: 4.0.0\n",
            "xgboost version:  2.1.1\n",
            "pandas version:  2.1.4\n",
            "seaborn version:  0.13.1\n",
            "matplotlib version:  3.7.1\n",
            "scikit-learn version 1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ▶️ **Up Next**  \n",
        "\n",
        "> Some _thorough_ Exploratory Data Analyis (EDA)"
      ],
      "metadata": {
        "id": "F4g7JnnMyMgB"
      }
    }
  ]
}